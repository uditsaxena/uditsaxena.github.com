---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm Udit Saxena. 

I am a Lead Machine Learning Engineer at [ASAPP](https://www.asapp.com/), where I work on large-scale AI infrastructure for Generative AI systems.

At ASAPP, I design and build retrieval-augmented generation (RAG) systems and multi-turn conversational agent platforms that power enterprise-scale voice and text AI products. My work spans workflow orchestration (Airflow, Spark, Kubernetes), LLM evaluation and proxy infrastructure (LiteLLM-style routing, telemetry), and distributed deep learning training.

I’ve also spoken at Airflow Summit 2024, sharing how ASAPP orchestrates large-scale batch inference for gen-AI workloads across Kubernetes clusters ([Airflow Blog](https://medium.com/apache-airflow/airflow-at-asapp-enhancing-ai-powered-contact-centers-0328deb6f03b)).

I collaborate closely with ASAPP's Research, Product, Platform, and SRE teams to bridge cutting-edge LLM research with production systems—ensuring our agents are reliable, grounded, and continuously improving through benchmark-driven evaluation.

Previously, as a Senior Machine Learning Engineer at [Sumo Logic](https://www.sumologic.com/) with [David A.](http://www.david-andrzejewski.com/), I built fast and approximate streaming clustering algorithms for text streams and time series models, resulting in two granted patents.

My research interests lie in the field of Machine Learning - specifically Natural Language Processing, geometric and topological methods in Deep Learning, and sparse approaches to Deep Learning. 

I recently published Scalable GPU-Accelerated Euler Characteristic Curves at NeurIPS 2025 ((NeurReps Workshop)[https://www.neurreps.org/]), introducing optimized and efficient differentiable topological features for PyTorch with 16–2000× GPU speedups on Ampere and later class GPUs.

In my work [A Unified Paths Perspective For Pruning at Initialization](https://arxiv.org/abs/2101.10552) with [Thomas Gebhart](https://www.gebhartom.com/), we investigate how paths through neural networks determine performance and what this path structure tells us about how to optimally prune networks using the framework of Neural Tangent Kernels.
    
In the past, at UMASS, I've worked with Microsoft Research (at Montreal and Cambridge) on [Active Learning](https://drive.google.com/open?id=1tzyhlQBIzi2rBTOM0YclZEZV-IN6fqNM), at [Lexalytics](https://www.lexalytics.com/) on Graph Convolutional Networks for Text Classification, with [Prof. Andrew McCallum](https://people.cs.umass.edu/~mccallum/) on [serving](https://github.com/iesl/factorie-tf-model-serve) pre-trained Tensorflow models for the JVM as part of [IESL](http://www.iesl.cs.umass.edu/), on a Pytorch [implementation](https://github.com/pytorch/examples/pull/191) of [End to End Memory Networks](http://arxiv.org/abs/1503.08895), as a Google Summer of Code intern, working with [MLPACK](https://github.com/mlpack/mlpack) (along with [Ryan Curtin](http://www.ratml.org/)), as a Product Engineer at [Sprinklr](http://www.sprinklr.com), and [Adobe](http://www.adobe.com/in/).

I enjoy the intersection of AI systems, distributed computing, and geometric ML, and I’m always interested in building tools and infrastructure that make large models more efficient, interpretable, and useful.

Check out my [resume](https://drive.google.com/file/d/1BzuVw7CUcC5_Vmv80IrLMVnJ7VI2Wics/view?usp=sharing)
